{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Estimator API Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aistudio.estimator3 import Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'aistudio.estimator3.Estimator'>\n"
     ]
    }
   ],
   "source": [
    "print(Estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/sky/dev/aistudio/workspace/ws-1', '/home/sky/anaconda3/envs/ai/lib/python37.zip', '/home/sky/anaconda3/envs/ai/lib/python3.7', '/home/sky/anaconda3/envs/ai/lib/python3.7/lib-dynload', '', '/home/sky/anaconda3/envs/ai/lib/python3.7/site-packages', '/home/sky/tmp/jupyterlab-git', '/home/sky/anaconda3/envs/ai/lib/python3.7/site-packages/IPython/extensions', '/home/sky/.ipython', '../../']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../aistudio/estimator3.py\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getfile(Estimator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "download_root = 'train-data'\n",
    "mnist_transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                           ,transforms.Normalize((0.1307,), (0.3081,))\n",
    "                           ])\n",
    "train_dataset  = datasets.MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "input_data_torch = train_dataset.data\n",
    "input_data_torch = torch.div(input_data_torch,255.)\n",
    "input_data_torch = torch.add(input_data_torch,-0.1307)\n",
    "input_data_torch = torch.div(input_data_torch,0.3081)\n",
    "input_data_torch = input_data_torch.unsqueeze(1)\n",
    "input_labels_torch = train_dataset.targets\n",
    "# Convert Tensor to Numpy\n",
    "input_data = input_data_torch.numpy()\n",
    "input_labels = input_labels_torch.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Check data type and shape\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(input_data))\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-info\">\n",
    "    Set Script Parameters\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':64,\n",
    "    'test-batch-size':128,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    #'no-cuda': True, # True is dummy value, value is always True\n",
    "    'nprocs':1,\n",
    "    #'loss':'cross_entropy',\n",
    "    'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'debug': True # True is dummy value, value is always True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1 (with model name in the aistudio service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(model_name=\"model-1\",script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(input_data,input_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile './estimator3_test.py'\n",
    "\n",
    "# from aistudio.estimator3 import Estimator\n",
    "# import torch\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "# download_root = 'train-data'\n",
    "# mnist_transform=transforms.Compose([\n",
    "#                            transforms.ToTensor()\n",
    "#                            ,transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                            ])\n",
    "# train_dataset  = datasets.MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "# input_data_torch = train_dataset.data\n",
    "# input_data_torch = torch.div(input_data_torch,255.)\n",
    "# input_data_torch = torch.add(input_data_torch,-0.1307)\n",
    "# input_data_torch = torch.div(input_data_torch,0.3081)\n",
    "# input_data_torch = input_data_torch.unsqueeze(1)\n",
    "# input_labels_torch = train_dataset.targets\n",
    "# # Convert Tensor to Numpy\n",
    "# input_data = input_data_torch.numpy()\n",
    "# input_labels = input_labels_torch.numpy()\n",
    "# script_params = {\n",
    "#     'epochs':5,\n",
    "#     'batch-size':64,\n",
    "#     'test-batch-size':128,\n",
    "#     'lr':0.01,\n",
    "#     'momentum':0.5,\n",
    "#     'seed':42,\n",
    "#     'log-interval':10,\n",
    "#     'no-cuda':False,\n",
    "#     'nprocs':1,\n",
    "#     'loss':'cross_entropy',\n",
    "#     'optimizer':'SGD'\n",
    "# }\n",
    "# estimator = Estimator(model_name=\"model-1\",script_params=script_params)\n",
    "# estimator.fit(input_data,input_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 2 (with model object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make network and load model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"./mnist_net.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(model_name=\"model-2\",script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(input_data,input_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED - Feel free to change\n",
    "modulename = \"torchnet\"\n",
    "######### DO NOT CHANGE #########\n",
    "filename = modulename + \".py\"\n",
    "filename = \"./nets/\" + filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Do not change code below at Line 1 to 3\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $filename\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':64,\n",
    "    'test-batch-size':128,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    #'loss':'cross_entropy',\n",
    "    'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'debug': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(input_data,input_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Scenario2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 1(MNIST-deeplearning.net)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change modulename\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "modulename = \"mnist-linear\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./nets/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $net_filename\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED - Feel free to change\n",
    "dataset_name = \"MNIST\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./datasets/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch\n",
    "import os\n",
    "\n",
    "class DatasetLoader:\n",
    "    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        \n",
    "        DATA_PATH = Path(\"datasets\")\n",
    "        PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "        PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        URL = \"http://deeplearning.net/data/mnist/\"\n",
    "        FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "        if not (PATH / FILENAME).exists():\n",
    "                content = requests.get(URL + FILENAME).content\n",
    "                (PATH / FILENAME).open(\"wb\").write(content)\n",
    "\n",
    "        with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "                ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")       \n",
    "\n",
    "        x_train, y_train, x_valid, y_valid = map(\n",
    "            torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    "        )\n",
    "        ### train_ds and valid_ds MUST BE TensorDataset(or ImageFolder or Torch Dataset Format)\n",
    "        self.train_dataset = TensorDataset(x_train, y_train)\n",
    "        self.valid_dataset = TensorDataset(x_valid, y_valid)\n",
    "        ####################################################\n",
    "        \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':64,\n",
    "    'test-batch-size':128,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    'loss':'cross_entropy',\n",
    "    #'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'debug': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 2(MNIST-torchvision)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change modulename\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "modulename = \"mnist-CNN\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./nets/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./nets/mnist-CNN.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $net_filename\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change dataset name\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "dataset_name = \"MNIST2\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./datasets/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/MNIST2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "class DatasetLoader:    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        thispath = os.path.dirname(os.path.abspath(__file__))\n",
    "        data_dir = os.path.join(thispath,\"MNIST2\")\n",
    "        mnist_transform=transforms.Compose([\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        train_dataset = datasets.MNIST(data_dir, transform=mnist_transform, train=True,  download=True)        \n",
    "        test_dataset  = datasets.MNIST(data_dir, transform=mnist_transform, train=False, download=True)\n",
    "        \n",
    "        ### train_ds and valid_ds MUST BE TensorDataset(or ImageFolder or Torch Dataset Format)\n",
    "        self.train_dataset = train_dataset\n",
    "        self.valid_dataset = test_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        ####################################################\n",
    "    \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':64,\n",
    "    'test-batch-size':128,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    #'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    #'loss':'cross_entropy',\n",
    "    'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'validation': True,\n",
    "    'debug': True    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--epochs', '5', '--batch-size', '64', '--test-batch-size', '128', '--lr', '0.01', '--momentum', '0.5', '--seed', '42', '--log-interval', '10', '--nprocs', '1', '--loss', 'nll_loss', '--optimizer', 'SGD', '--validation', '--debug', '--net-name', 'mnist-CNN']\n"
     ]
    }
   ],
   "source": [
    "estimator = Estimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Requested to Portal.\n",
      "[1,0]<stdout>:Namespace(batch_size=64, dataset_loader='MNIST2', debug=True, epochs=5, log_interval=10, loss='nll_loss', lr=0.01, model_path=None, momentum=0.5, net_name='mnist-CNN', no_cuda=False, nprocs=1, optimizer='SGD', seed=42, test_batch_size=128, use_adasum=False, validation=True)\n",
      "[1,0]<stdout>:Arguments Parsing Finished.\n",
      "[1,0]<stdout>:CUDA Supported!\n",
      "[1,0]<stdout>:Network was found.\n",
      "[1,0]<stdout>:Model's state_dict:\n",
      "[1,0]<stdout>:conv1.weight \t torch.Size([10, 1, 5, 5])\n",
      "[1,0]<stdout>:conv1.bias \t torch.Size([10])\n",
      "[1,0]<stdout>:conv2.weight \t torch.Size([20, 10, 5, 5])\n",
      "[1,0]<stdout>:conv2.bias \t torch.Size([20])\n",
      "[1,0]<stdout>:fc1.weight \t torch.Size([50, 320])\n",
      "[1,0]<stdout>:fc1.bias \t torch.Size([50])\n",
      "[1,0]<stdout>:fc2.weight \t torch.Size([10, 50])\n",
      "[1,0]<stdout>:fc2.bias \t torch.Size([10])\n",
      "[1,0]<stdout>:Optimizer's state_dict:\n",
      "[1,0]<stdout>:state \t {}\n",
      "[1,0]<stdout>:param_groups \t [{'lr': 0.009999999776482582, 'momentum': 0.5, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140316693636192, 140316693636272, 140316693636752, 140316693636832, 140316693636912, 140316693636992, 140316693636672, 140316693637072]}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.register_model(model_name=\"mnist-good-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 3(CIFAR10)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED - Feel free to change\n",
    "modulename = \"CIFAR10-CNN\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./nets/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $net_filename\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change dataset name\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "dataset_name = \"CIFAR10\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./datasets/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "\n",
    "class DatasetLoader:    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        thispath = os.path.dirname(os.path.abspath(__file__))\n",
    "        data_dir = os.path.join(thispath,\"CIFAR10\")\n",
    "        trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True,\n",
    "                                                download=True, transform=transform)\n",
    "        testset = torchvision.datasets.CIFAR10(root=data_dir, train=False,\n",
    "                                               download=True, transform=transform)\n",
    "        self.train_dataset = trainset\n",
    "        self.valid_dataset = testset\n",
    "        self.test_dataset = testset\n",
    "        ####################################################\n",
    "        \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':32,\n",
    "    'test-batch-size':64,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.9,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    #'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    'loss':'cross_entropy',\n",
    "    #'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'debug': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 4(hymenoptera)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED - Feel free to change\n",
    "modulename = \"resnet18\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./nets/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $net_filename\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):        \n",
    "        super(Net, self).__init__()        \n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        # Here the size of each output sample is set to 2.\n",
    "        # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "        self.model.fc = nn.Linear(num_ftrs, 2)        \n",
    "        #self.add_module(\"resnet18\", self.model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change dataset name\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "dataset_name = \"hymenoptera\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./datasets/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "\n",
    "class DatasetLoader:    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        # Just normalization for validation\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "        }\n",
    "        thispath = os.path.dirname(os.path.abspath(__file__))\n",
    "        data_dir = os.path.join(thispath,\"hymenoptera_data\")        \n",
    "        image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                                  data_transforms[x])\n",
    "                          for x in ['train', 'val']}\n",
    "        self.train_dataset = image_datasets['train']\n",
    "        self.valid_dataset = image_datasets['val']\n",
    "        ####################################################\n",
    "        \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'datasets/hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':25,\n",
    "    'batch-size':4,\n",
    "    'test-batch-size':8,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    #'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    'loss':'cross_entropy',\n",
    "    #'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'validation': True,\n",
    "    'debug': True    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 5(MNIST-.csv, .png)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED - Feel free to change\n",
    "modulename = \"mnist-csv\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./nets/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $net_filename\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change dataset name\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "dataset_name = \"mnist-images\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./datasets/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "class DatasetLoader:    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        # Just normalization for validation        \n",
    "        mnist_transform=transforms.Compose([transforms.Grayscale(),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        thispath = os.path.dirname(os.path.abspath(__file__))\n",
    "        data_dir = os.path.join(thispath,\"image-datasets\",\"mnist\",\"images\")\n",
    "        image_dataset = torchvision.datasets.ImageFolder(data_dir,mnist_transform)\n",
    "        \n",
    "        self.train_dataset = image_dataset\n",
    "        ####################################################\n",
    "        \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':32,\n",
    "    'test-batch-size':64,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    'no-cuda':True,\n",
    "    'nprocs':1,\n",
    "    #'loss':'cross_entropy',\n",
    "    'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'debug': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
