{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Estimator API Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srdaistudio.torchestimator import TorchEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'aistudio.torchestimator.TorchEstimator'>\n"
     ]
    }
   ],
   "source": [
    "print(TorchEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/sky/dev/aistudio/workspace/ws-1', '/home/sky/anaconda3/envs/ai/lib/python37.zip', '/home/sky/anaconda3/envs/ai/lib/python3.7', '/home/sky/anaconda3/envs/ai/lib/python3.7/lib-dynload', '', '/home/sky/anaconda3/envs/ai/lib/python3.7/site-packages', '/home/sky/tmp/jupyterlab-git', '/home/sky/anaconda3/envs/ai/lib/python3.7/site-packages/IPython/extensions', '/home/sky/.ipython', '../../']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../aistudio/torchestimator.py\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getfile(TorchEstimator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Scenario2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 1(MNIST-deeplearning.net)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change modulename\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "modulename = \"mnist-linear\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./net/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./net/mnist-linear.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $net_filename\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name(USER-DEFINED) - Feel free to change\n",
    "dataset_name = \"MNIST\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./dataset/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./dataset/MNIST.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch\n",
    "import os\n",
    "\n",
    "class DatasetLoader:\n",
    "    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        \n",
    "        DATA_PATH = Path(\"dataset\")\n",
    "        PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "        PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        URL = \"http://deeplearning.net/data/mnist/\"\n",
    "        FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "        if not (PATH / FILENAME).exists():\n",
    "                content = requests.get(URL + FILENAME).content\n",
    "                (PATH / FILENAME).open(\"wb\").write(content)\n",
    "\n",
    "        with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "                ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")       \n",
    "\n",
    "        x_train, y_train, x_valid, y_valid = map(\n",
    "            torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    "        )\n",
    "        ### train_ds and valid_ds MUST BE TensorDataset(or ImageFolder or Torch Dataset Format)\n",
    "        self.train_dataset = TensorDataset(x_train, y_train)\n",
    "        self.valid_dataset = TensorDataset(x_valid, y_valid)\n",
    "        ####################################################\n",
    "        \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':64,\n",
    "    'test-batch-size':128,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    'loss':'cross_entropy',\n",
    "    #'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'validation': True,\n",
    "    'debug': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sky/dev/aistudio/workspace/ws-1\n",
      "Workspace path was found.\n",
      "/home/sky/dev/aistudio/workspace/ws-1/job\n",
      "['--epochs', '5', '--batch-size', '64', '--test-batch-size', '128', '--lr', '0.01', '--momentum', '0.5', '--seed', '42', '--log-interval', '10', '--no-cuda', '--nprocs', '1', '--loss', 'cross_entropy', '--optimizer', 'SGD', '--validation', '--debug', '--net-name', 'mnist-linear']\n"
     ]
    }
   ],
   "source": [
    "estimator = TorchEstimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Requested to Portal.\n",
      "[1,0]<stdout>:Arguments Parsing Finished.\n",
      "[1,0]<stdout>:Namespace(batch_size=64, dataset_loader='MNIST', debug=True, epochs=5, log_interval=10, loss='cross_entropy', lr=0.01, model_path=None, momentum=0.5, net_name='mnist-linear', no_cuda=True, nprocs=1, optimizer='SGD', prediction=False, seed=42, test_batch_size=128, use_adasum=False, validation=True)\n",
      "[1,0]<stdout>:CUDA Not Supported!\n",
      "[1,0]<stdout>:Network was found.\n",
      "[1,0]<stdout>:Model's state_dict:\n",
      "[1,0]<stdout>:lin.weight \t torch.Size([10, 784])\n",
      "[1,0]<stdout>:lin.bias \t torch.Size([10])\n",
      "[1,0]<stdout>:Optimizer's state_dict:\n",
      "[1,0]<stdout>:state \t {}\n",
      "[1,0]<stdout>:param_groups \t [{'lr': 0.009999999776482582, 'momentum': 0.5, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140339595894208, 140339580451328]}]\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [640/50000 (1%)]\tLoss: 2.079029\tAccuracy: 51.5625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [1280/50000 (3%)]\tLoss: 1.974339\tAccuracy: 56.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [1920/50000 (4%)]\tLoss: 1.831641\tAccuracy: 67.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [2560/50000 (5%)]\tLoss: 1.693138\tAccuracy: 67.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [3200/50000 (6%)]\tLoss: 1.518662\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [3840/50000 (8%)]\tLoss: 1.400446\tAccuracy: 78.125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [4480/50000 (9%)]\tLoss: 1.243659\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [5120/50000 (10%)]\tLoss: 1.340446\tAccuracy: 70.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [5760/50000 (12%)]\tLoss: 1.270026\tAccuracy: 79.6875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.268296\tAccuracy: 70.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [7040/50000 (14%)]\tLoss: 1.144608\tAccuracy: 78.125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [7680/50000 (15%)]\tLoss: 1.255849\tAccuracy: 70.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [8320/50000 (17%)]\tLoss: 1.090631\tAccuracy: 79.6875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [8960/50000 (18%)]\tLoss: 1.046396\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [9600/50000 (19%)]\tLoss: 0.955691\tAccuracy: 76.5625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [10240/50000 (20%)]\tLoss: 0.959506\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [10880/50000 (22%)]\tLoss: 0.891331\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [11520/50000 (23%)]\tLoss: 0.773468\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [12160/50000 (24%)]\tLoss: 0.933472\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [12800/50000 (26%)]\tLoss: 0.950871\tAccuracy: 76.5625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [13440/50000 (27%)]\tLoss: 0.980951\tAccuracy: 79.6875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [14080/50000 (28%)]\tLoss: 0.817716\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [14720/50000 (29%)]\tLoss: 0.888696\tAccuracy: 75.0\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [15360/50000 (31%)]\tLoss: 0.937894\tAccuracy: 78.125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [16000/50000 (32%)]\tLoss: 0.808485\tAccuracy: 79.6875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [16640/50000 (33%)]\tLoss: 0.711296\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [17280/50000 (35%)]\tLoss: 0.800694\tAccuracy: 78.125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [17920/50000 (36%)]\tLoss: 0.638047\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [18560/50000 (37%)]\tLoss: 0.781437\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [19200/50000 (38%)]\tLoss: 0.860097\tAccuracy: 79.6875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [19840/50000 (40%)]\tLoss: 0.797971\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [20480/50000 (41%)]\tLoss: 0.754913\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [21120/50000 (42%)]\tLoss: 0.663025\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [21760/50000 (43%)]\tLoss: 0.706039\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [22400/50000 (45%)]\tLoss: 0.834571\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [23040/50000 (46%)]\tLoss: 0.813008\tAccuracy: 76.5625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [23680/50000 (47%)]\tLoss: 0.801602\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [24320/50000 (49%)]\tLoss: 0.501503\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [24960/50000 (50%)]\tLoss: 0.703466\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.654844\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [26240/50000 (52%)]\tLoss: 0.926576\tAccuracy: 75.0\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [26880/50000 (54%)]\tLoss: 0.664060\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [27520/50000 (55%)]\tLoss: 0.559562\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [28160/50000 (56%)]\tLoss: 0.590075\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [28800/50000 (58%)]\tLoss: 0.499614\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [29440/50000 (59%)]\tLoss: 0.636826\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [30080/50000 (60%)]\tLoss: 0.578488\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [30720/50000 (61%)]\tLoss: 0.635978\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [31360/50000 (63%)]\tLoss: 0.637341\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [32000/50000 (64%)]\tLoss: 0.533463\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [32640/50000 (65%)]\tLoss: 0.448290\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [33280/50000 (66%)]\tLoss: 0.588761\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [33920/50000 (68%)]\tLoss: 0.520195\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [34560/50000 (69%)]\tLoss: 0.502277\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [35200/50000 (70%)]\tLoss: 0.559479\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [35840/50000 (72%)]\tLoss: 0.526169\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [36480/50000 (73%)]\tLoss: 0.754488\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [37120/50000 (74%)]\tLoss: 0.674034\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [37760/50000 (75%)]\tLoss: 0.449997\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.636110\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [39040/50000 (78%)]\tLoss: 0.499855\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [39680/50000 (79%)]\tLoss: 0.473281\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [40320/50000 (81%)]\tLoss: 0.594087\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [40960/50000 (82%)]\tLoss: 0.521275\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [41600/50000 (83%)]\tLoss: 0.582831\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [42240/50000 (84%)]\tLoss: 0.444674\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [42880/50000 (86%)]\tLoss: 0.772323\tAccuracy: 75.0\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [43520/50000 (87%)]\tLoss: 0.655797\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [44160/50000 (88%)]\tLoss: 0.641330\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.523720\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [45440/50000 (91%)]\tLoss: 0.643673\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [46080/50000 (92%)]\tLoss: 0.476605\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [46720/50000 (93%)]\tLoss: 0.771622\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [47360/50000 (95%)]\tLoss: 0.603615\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [48000/50000 (96%)]\tLoss: 0.555952\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [48640/50000 (97%)]\tLoss: 0.379664\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [49280/50000 (98%)]\tLoss: 0.509814\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 1 [49920/50000 (100%)]\tLoss: 0.517500\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Train\n",
      "[1,0]<stdout>:Epoch 1/5\n",
      "[1,0]<stdout>:Loss: 0.8266 Acc: 82.4880\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [640/10000 (6%)]\tLoss: 0.573838\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [1280/10000 (13%)]\tLoss: 0.321552\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [1920/10000 (19%)]\tLoss: 0.624804\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [2560/10000 (25%)]\tLoss: 0.422487\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [3200/10000 (32%)]\tLoss: 0.584910\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [3840/10000 (38%)]\tLoss: 0.446499\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [4480/10000 (45%)]\tLoss: 0.436977\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [5120/10000 (51%)]\tLoss: 0.441959\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [5760/10000 (57%)]\tLoss: 0.451866\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [6400/10000 (64%)]\tLoss: 0.443791\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [7040/10000 (70%)]\tLoss: 0.450612\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [7680/10000 (76%)]\tLoss: 0.465005\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [8320/10000 (83%)]\tLoss: 0.443151\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [8960/10000 (89%)]\tLoss: 0.630080\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 1 [9600/10000 (96%)]\tLoss: 0.523424\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Validation\n",
      "[1,0]<stdout>:Epoch 1/5\n",
      "[1,0]<stdout>:Loss: 0.4889 Acc: 88.5400\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [640/50000 (1%)]\tLoss: 0.582816\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [1280/50000 (3%)]\tLoss: 0.405753\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [1920/50000 (4%)]\tLoss: 0.567957\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [2560/50000 (5%)]\tLoss: 0.625115\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [3200/50000 (6%)]\tLoss: 0.433268\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [3840/50000 (8%)]\tLoss: 0.529244\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [4480/50000 (9%)]\tLoss: 0.451924\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [5120/50000 (10%)]\tLoss: 0.654568\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [5760/50000 (12%)]\tLoss: 0.495658\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.329281\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [7040/50000 (14%)]\tLoss: 0.511657\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [7680/50000 (15%)]\tLoss: 0.624429\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [8320/50000 (17%)]\tLoss: 0.501939\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [8960/50000 (18%)]\tLoss: 0.494108\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [9600/50000 (19%)]\tLoss: 0.478176\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [10240/50000 (20%)]\tLoss: 0.420194\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [10880/50000 (22%)]\tLoss: 0.369675\tAccuracy: 96.875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [11520/50000 (23%)]\tLoss: 0.442080\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [12160/50000 (24%)]\tLoss: 0.412122\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.551390\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [13440/50000 (27%)]\tLoss: 0.422905\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [14080/50000 (28%)]\tLoss: 0.563751\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [14720/50000 (29%)]\tLoss: 0.515198\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [15360/50000 (31%)]\tLoss: 0.625707\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [16000/50000 (32%)]\tLoss: 0.602489\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [16640/50000 (33%)]\tLoss: 0.500603\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [17280/50000 (35%)]\tLoss: 0.628020\tAccuracy: 78.125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [17920/50000 (36%)]\tLoss: 0.441149\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [18560/50000 (37%)]\tLoss: 0.355720\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.486017\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [19840/50000 (40%)]\tLoss: 0.381912\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [20480/50000 (41%)]\tLoss: 0.546767\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [21120/50000 (42%)]\tLoss: 0.429168\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [21760/50000 (43%)]\tLoss: 0.664764\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [22400/50000 (45%)]\tLoss: 0.330300\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [23040/50000 (46%)]\tLoss: 0.377903\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [23680/50000 (47%)]\tLoss: 0.470559\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [24320/50000 (49%)]\tLoss: 0.452380\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [24960/50000 (50%)]\tLoss: 0.464322\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.561383\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [26240/50000 (52%)]\tLoss: 0.517268\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [26880/50000 (54%)]\tLoss: 0.587174\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [27520/50000 (55%)]\tLoss: 0.399272\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [28160/50000 (56%)]\tLoss: 0.522207\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [28800/50000 (58%)]\tLoss: 0.579201\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [29440/50000 (59%)]\tLoss: 0.355382\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [30080/50000 (60%)]\tLoss: 0.447615\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [30720/50000 (61%)]\tLoss: 0.366040\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [31360/50000 (63%)]\tLoss: 0.450841\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.447147\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [32640/50000 (65%)]\tLoss: 0.482388\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [33280/50000 (66%)]\tLoss: 0.439753\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [33920/50000 (68%)]\tLoss: 0.484127\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [34560/50000 (69%)]\tLoss: 0.398253\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [35200/50000 (70%)]\tLoss: 0.436220\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [35840/50000 (72%)]\tLoss: 0.456245\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [36480/50000 (73%)]\tLoss: 0.417102\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [37120/50000 (74%)]\tLoss: 0.380263\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [37760/50000 (75%)]\tLoss: 0.409102\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.345492\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [39040/50000 (78%)]\tLoss: 0.482049\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [39680/50000 (79%)]\tLoss: 0.362424\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [40320/50000 (81%)]\tLoss: 0.469827\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [40960/50000 (82%)]\tLoss: 0.537590\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [41600/50000 (83%)]\tLoss: 0.421154\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [42240/50000 (84%)]\tLoss: 0.360253\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [42880/50000 (86%)]\tLoss: 0.546406\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [43520/50000 (87%)]\tLoss: 0.552249\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [44160/50000 (88%)]\tLoss: 0.339619\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.521785\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [45440/50000 (91%)]\tLoss: 0.428277\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [46080/50000 (92%)]\tLoss: 0.625449\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [46720/50000 (93%)]\tLoss: 0.375226\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [47360/50000 (95%)]\tLoss: 0.539194\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.481300\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [48640/50000 (97%)]\tLoss: 0.501725\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [49280/50000 (98%)]\tLoss: 0.529471\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 2 [49920/50000 (100%)]\tLoss: 0.420174\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Train\n",
      "[1,0]<stdout>:Epoch 2/5\n",
      "[1,0]<stdout>:Loss: 0.4823 Acc: 87.6240\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [640/10000 (6%)]\tLoss: 0.370486\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [1280/10000 (13%)]\tLoss: 0.615890\tAccuracy: 79.6875\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [1920/10000 (19%)]\tLoss: 0.445640\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [2560/10000 (25%)]\tLoss: 0.465778\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [3200/10000 (32%)]\tLoss: 0.270254\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [3840/10000 (38%)]\tLoss: 0.379574\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [4480/10000 (45%)]\tLoss: 0.365043\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [5120/10000 (51%)]\tLoss: 0.587162\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [5760/10000 (57%)]\tLoss: 0.239275\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [6400/10000 (64%)]\tLoss: 0.357145\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [7040/10000 (70%)]\tLoss: 0.452956\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [7680/10000 (76%)]\tLoss: 0.357342\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [8320/10000 (83%)]\tLoss: 0.240591\tAccuracy: 100.0\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [8960/10000 (89%)]\tLoss: 0.453740\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 2 [9600/10000 (96%)]\tLoss: 0.448989\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Validation\n",
      "[1,0]<stdout>:Epoch 2/5\n",
      "[1,0]<stdout>:Loss: 0.4030 Acc: 89.7700\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [640/50000 (1%)]\tLoss: 0.655489\tAccuracy: 79.6875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [1280/50000 (3%)]\tLoss: 0.433738\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [1920/50000 (4%)]\tLoss: 0.559194\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [2560/50000 (5%)]\tLoss: 0.343888\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [3200/50000 (6%)]\tLoss: 0.410041\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [3840/50000 (8%)]\tLoss: 0.388448\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [4480/50000 (9%)]\tLoss: 0.275380\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [5120/50000 (10%)]\tLoss: 0.379312\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [5760/50000 (12%)]\tLoss: 0.383392\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.478314\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [7040/50000 (14%)]\tLoss: 0.403910\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [7680/50000 (15%)]\tLoss: 0.360634\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [8320/50000 (17%)]\tLoss: 0.386099\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [8960/50000 (18%)]\tLoss: 0.310651\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [9600/50000 (19%)]\tLoss: 0.411190\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [10240/50000 (20%)]\tLoss: 0.234027\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [10880/50000 (22%)]\tLoss: 0.513133\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [11520/50000 (23%)]\tLoss: 0.338058\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [12160/50000 (24%)]\tLoss: 0.583565\tAccuracy: 79.6875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.439881\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [13440/50000 (27%)]\tLoss: 0.400583\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [14080/50000 (28%)]\tLoss: 0.471261\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [14720/50000 (29%)]\tLoss: 0.585719\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [15360/50000 (31%)]\tLoss: 0.397031\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.499781\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [16640/50000 (33%)]\tLoss: 0.286932\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [17280/50000 (35%)]\tLoss: 0.436712\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [17920/50000 (36%)]\tLoss: 0.306184\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [18560/50000 (37%)]\tLoss: 0.499190\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.431783\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [19840/50000 (40%)]\tLoss: 0.455002\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [20480/50000 (41%)]\tLoss: 0.373194\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [21120/50000 (42%)]\tLoss: 0.382261\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [21760/50000 (43%)]\tLoss: 0.408851\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [22400/50000 (45%)]\tLoss: 0.300743\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [23040/50000 (46%)]\tLoss: 0.329979\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [23680/50000 (47%)]\tLoss: 0.316327\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [24320/50000 (49%)]\tLoss: 0.262434\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [24960/50000 (50%)]\tLoss: 0.320658\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.657457\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [26240/50000 (52%)]\tLoss: 0.594027\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [26880/50000 (54%)]\tLoss: 0.434321\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [27520/50000 (55%)]\tLoss: 0.415477\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [28160/50000 (56%)]\tLoss: 0.379596\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [28800/50000 (58%)]\tLoss: 0.428193\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [29440/50000 (59%)]\tLoss: 0.411410\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [30080/50000 (60%)]\tLoss: 0.348288\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [30720/50000 (61%)]\tLoss: 0.356697\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [31360/50000 (63%)]\tLoss: 0.514316\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.387959\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [32640/50000 (65%)]\tLoss: 0.254022\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [33280/50000 (66%)]\tLoss: 0.544000\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [33920/50000 (68%)]\tLoss: 0.516128\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [34560/50000 (69%)]\tLoss: 0.417658\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [35200/50000 (70%)]\tLoss: 0.461326\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [35840/50000 (72%)]\tLoss: 0.407771\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [36480/50000 (73%)]\tLoss: 0.460014\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [37120/50000 (74%)]\tLoss: 0.558543\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [37760/50000 (75%)]\tLoss: 0.435283\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.336338\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [39040/50000 (78%)]\tLoss: 0.350779\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [39680/50000 (79%)]\tLoss: 0.447557\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [40320/50000 (81%)]\tLoss: 0.506092\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [40960/50000 (82%)]\tLoss: 0.382956\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [41600/50000 (83%)]\tLoss: 0.207746\tAccuracy: 96.875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [42240/50000 (84%)]\tLoss: 0.291349\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [42880/50000 (86%)]\tLoss: 0.227870\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [43520/50000 (87%)]\tLoss: 0.318749\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [44160/50000 (88%)]\tLoss: 0.386814\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.534385\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [45440/50000 (91%)]\tLoss: 0.232663\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [46080/50000 (92%)]\tLoss: 0.404554\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [46720/50000 (93%)]\tLoss: 0.475175\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [47360/50000 (95%)]\tLoss: 0.374930\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.367933\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [48640/50000 (97%)]\tLoss: 0.434371\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [49280/50000 (98%)]\tLoss: 0.390797\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 3 [49920/50000 (100%)]\tLoss: 0.436974\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Train\n",
      "[1,0]<stdout>:Epoch 3/5\n",
      "[1,0]<stdout>:Loss: 0.4232 Acc: 88.7660\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [640/10000 (6%)]\tLoss: 0.640297\tAccuracy: 73.4375\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [1280/10000 (13%)]\tLoss: 0.393387\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [1920/10000 (19%)]\tLoss: 0.257922\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [2560/10000 (25%)]\tLoss: 0.303977\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [3200/10000 (32%)]\tLoss: 0.486972\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [3840/10000 (38%)]\tLoss: 0.390343\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [4480/10000 (45%)]\tLoss: 0.256554\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [5120/10000 (51%)]\tLoss: 0.310641\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [5760/10000 (57%)]\tLoss: 0.306088\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [6400/10000 (64%)]\tLoss: 0.459172\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [7040/10000 (70%)]\tLoss: 0.449916\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [7680/10000 (76%)]\tLoss: 0.318253\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [8320/10000 (83%)]\tLoss: 0.341600\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [8960/10000 (89%)]\tLoss: 0.347379\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 3 [9600/10000 (96%)]\tLoss: 0.268203\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Validation\n",
      "[1,0]<stdout>:Epoch 3/5\n",
      "[1,0]<stdout>:Loss: 0.3689 Acc: 90.5900\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [640/50000 (1%)]\tLoss: 0.423839\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [1280/50000 (3%)]\tLoss: 0.452340\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [1920/50000 (4%)]\tLoss: 0.524070\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [2560/50000 (5%)]\tLoss: 0.440342\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [3200/50000 (6%)]\tLoss: 0.361038\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [3840/50000 (8%)]\tLoss: 0.478800\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [4480/50000 (9%)]\tLoss: 0.550294\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [5120/50000 (10%)]\tLoss: 0.401484\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [5760/50000 (12%)]\tLoss: 0.600394\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [6400/50000 (13%)]\tLoss: 0.371611\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [7040/50000 (14%)]\tLoss: 0.448091\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [7680/50000 (15%)]\tLoss: 0.554293\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [8320/50000 (17%)]\tLoss: 0.392924\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [8960/50000 (18%)]\tLoss: 0.379294\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [9600/50000 (19%)]\tLoss: 0.432485\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [10240/50000 (20%)]\tLoss: 0.352390\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [10880/50000 (22%)]\tLoss: 0.383286\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [11520/50000 (23%)]\tLoss: 0.377833\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [12160/50000 (24%)]\tLoss: 0.317429\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.588108\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [13440/50000 (27%)]\tLoss: 0.388454\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [14080/50000 (28%)]\tLoss: 0.376560\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [14720/50000 (29%)]\tLoss: 0.663945\tAccuracy: 79.6875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [15360/50000 (31%)]\tLoss: 0.477649\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [16000/50000 (32%)]\tLoss: 0.489283\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [16640/50000 (33%)]\tLoss: 0.336055\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [17280/50000 (35%)]\tLoss: 0.551458\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [17920/50000 (36%)]\tLoss: 0.279273\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [18560/50000 (37%)]\tLoss: 0.473722\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [19200/50000 (38%)]\tLoss: 0.379805\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [19840/50000 (40%)]\tLoss: 0.223147\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [20480/50000 (41%)]\tLoss: 0.242923\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [21120/50000 (42%)]\tLoss: 0.407558\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [21760/50000 (43%)]\tLoss: 0.371756\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [22400/50000 (45%)]\tLoss: 0.408419\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [23040/50000 (46%)]\tLoss: 0.212612\tAccuracy: 96.875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [23680/50000 (47%)]\tLoss: 0.274655\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [24320/50000 (49%)]\tLoss: 0.394579\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [24960/50000 (50%)]\tLoss: 0.304184\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.367808\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [26240/50000 (52%)]\tLoss: 0.429601\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [26880/50000 (54%)]\tLoss: 0.445019\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [27520/50000 (55%)]\tLoss: 0.432772\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [28160/50000 (56%)]\tLoss: 0.388013\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [28800/50000 (58%)]\tLoss: 0.562803\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [29440/50000 (59%)]\tLoss: 0.283910\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [30080/50000 (60%)]\tLoss: 0.451806\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [30720/50000 (61%)]\tLoss: 0.267035\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [31360/50000 (63%)]\tLoss: 0.268951\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.272918\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [32640/50000 (65%)]\tLoss: 0.192580\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [33280/50000 (66%)]\tLoss: 0.229282\tAccuracy: 96.875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [33920/50000 (68%)]\tLoss: 0.452815\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [34560/50000 (69%)]\tLoss: 0.194995\tAccuracy: 96.875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [35200/50000 (70%)]\tLoss: 0.190718\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [35840/50000 (72%)]\tLoss: 0.434863\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [36480/50000 (73%)]\tLoss: 0.312146\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [37120/50000 (74%)]\tLoss: 0.433163\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [37760/50000 (75%)]\tLoss: 0.443256\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.298711\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [39040/50000 (78%)]\tLoss: 0.283306\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [39680/50000 (79%)]\tLoss: 0.306079\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [40320/50000 (81%)]\tLoss: 0.594811\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [40960/50000 (82%)]\tLoss: 0.216923\tAccuracy: 96.875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [41600/50000 (83%)]\tLoss: 0.481799\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [42240/50000 (84%)]\tLoss: 0.445782\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [42880/50000 (86%)]\tLoss: 0.341604\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [43520/50000 (87%)]\tLoss: 0.513692\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [44160/50000 (88%)]\tLoss: 0.515357\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.439535\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [45440/50000 (91%)]\tLoss: 0.406375\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [46080/50000 (92%)]\tLoss: 0.590248\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [46720/50000 (93%)]\tLoss: 0.491812\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [47360/50000 (95%)]\tLoss: 0.278595\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [48000/50000 (96%)]\tLoss: 0.355339\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [48640/50000 (97%)]\tLoss: 0.358828\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [49280/50000 (98%)]\tLoss: 0.360879\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 4 [49920/50000 (100%)]\tLoss: 0.437430\tAccuracy: 87.5\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Train\n",
      "[1,0]<stdout>:Epoch 4/5\n",
      "[1,0]<stdout>:Loss: 0.3938 Acc: 89.3740\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [640/10000 (6%)]\tLoss: 0.340617\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [1280/10000 (13%)]\tLoss: 0.251504\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [1920/10000 (19%)]\tLoss: 0.420235\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [2560/10000 (25%)]\tLoss: 0.544016\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [3200/10000 (32%)]\tLoss: 0.287132\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [3840/10000 (38%)]\tLoss: 0.312926\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [4480/10000 (45%)]\tLoss: 0.248579\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [5120/10000 (51%)]\tLoss: 0.414564\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [5760/10000 (57%)]\tLoss: 0.401580\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [6400/10000 (64%)]\tLoss: 0.217321\tAccuracy: 100.0\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [7040/10000 (70%)]\tLoss: 0.217722\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [7680/10000 (76%)]\tLoss: 0.459513\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [8320/10000 (83%)]\tLoss: 0.253367\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [8960/10000 (89%)]\tLoss: 0.343032\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 4 [9600/10000 (96%)]\tLoss: 0.312284\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Validation\n",
      "[1,0]<stdout>:Epoch 4/5\n",
      "[1,0]<stdout>:Loss: 0.3502 Acc: 90.6100\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [640/50000 (1%)]\tLoss: 0.355849\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [1280/50000 (3%)]\tLoss: 0.383553\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [1920/50000 (4%)]\tLoss: 0.255911\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [2560/50000 (5%)]\tLoss: 0.387184\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [3200/50000 (6%)]\tLoss: 0.411295\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [3840/50000 (8%)]\tLoss: 0.517879\tAccuracy: 79.6875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [4480/50000 (9%)]\tLoss: 0.291199\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [5120/50000 (10%)]\tLoss: 0.265343\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [5760/50000 (12%)]\tLoss: 0.365115\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.671548\tAccuracy: 78.125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [7040/50000 (14%)]\tLoss: 0.316396\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [7680/50000 (15%)]\tLoss: 0.161389\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [8320/50000 (17%)]\tLoss: 0.417477\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [8960/50000 (18%)]\tLoss: 0.398004\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [9600/50000 (19%)]\tLoss: 0.369890\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [10240/50000 (20%)]\tLoss: 0.698399\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [10880/50000 (22%)]\tLoss: 0.232170\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [11520/50000 (23%)]\tLoss: 0.416823\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [12160/50000 (24%)]\tLoss: 0.258365\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.376539\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [13440/50000 (27%)]\tLoss: 0.462424\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [14080/50000 (28%)]\tLoss: 0.493551\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [14720/50000 (29%)]\tLoss: 0.511325\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [15360/50000 (31%)]\tLoss: 0.371508\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [16000/50000 (32%)]\tLoss: 0.487519\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [16640/50000 (33%)]\tLoss: 0.628748\tAccuracy: 81.25\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [17280/50000 (35%)]\tLoss: 0.267388\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [17920/50000 (36%)]\tLoss: 0.353491\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [18560/50000 (37%)]\tLoss: 0.309896\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.438204\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [19840/50000 (40%)]\tLoss: 0.308002\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [20480/50000 (41%)]\tLoss: 0.411805\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [21120/50000 (42%)]\tLoss: 0.400996\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [21760/50000 (43%)]\tLoss: 0.323396\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [22400/50000 (45%)]\tLoss: 0.385421\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [23040/50000 (46%)]\tLoss: 0.409571\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [23680/50000 (47%)]\tLoss: 0.326639\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [24320/50000 (49%)]\tLoss: 0.550436\tAccuracy: 84.375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [24960/50000 (50%)]\tLoss: 0.322891\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.445349\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [26240/50000 (52%)]\tLoss: 0.342240\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [26880/50000 (54%)]\tLoss: 0.289685\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [27520/50000 (55%)]\tLoss: 0.299257\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [28160/50000 (56%)]\tLoss: 0.370742\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [28800/50000 (58%)]\tLoss: 0.315547\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [29440/50000 (59%)]\tLoss: 0.341682\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [30080/50000 (60%)]\tLoss: 0.294369\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [30720/50000 (61%)]\tLoss: 0.304796\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [31360/50000 (63%)]\tLoss: 0.385280\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.321912\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [32640/50000 (65%)]\tLoss: 0.421508\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [33280/50000 (66%)]\tLoss: 0.398203\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [33920/50000 (68%)]\tLoss: 0.377095\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [34560/50000 (69%)]\tLoss: 0.449307\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [35200/50000 (70%)]\tLoss: 0.296489\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [35840/50000 (72%)]\tLoss: 0.383664\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [36480/50000 (73%)]\tLoss: 0.221918\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [37120/50000 (74%)]\tLoss: 0.319222\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [37760/50000 (75%)]\tLoss: 0.457276\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.282880\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [39040/50000 (78%)]\tLoss: 0.485161\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [39680/50000 (79%)]\tLoss: 0.420345\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [40320/50000 (81%)]\tLoss: 0.344154\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [40960/50000 (82%)]\tLoss: 0.450231\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [41600/50000 (83%)]\tLoss: 0.446259\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [42240/50000 (84%)]\tLoss: 0.348140\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [42880/50000 (86%)]\tLoss: 0.298826\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [43520/50000 (87%)]\tLoss: 0.316413\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [44160/50000 (88%)]\tLoss: 0.415972\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.437951\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [45440/50000 (91%)]\tLoss: 0.245943\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [46080/50000 (92%)]\tLoss: 0.446701\tAccuracy: 82.8125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [46720/50000 (93%)]\tLoss: 0.350446\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [47360/50000 (95%)]\tLoss: 0.329554\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [48000/50000 (96%)]\tLoss: 0.347678\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [48640/50000 (97%)]\tLoss: 0.392686\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [49280/50000 (98%)]\tLoss: 0.338717\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Train Epoch: 5 [49920/50000 (100%)]\tLoss: 0.402813\tAccuracy: 87.5\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Train\n",
      "[1,0]<stdout>:Epoch 5/5\n",
      "[1,0]<stdout>:Loss: 0.3754 Acc: 89.6900\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [640/10000 (6%)]\tLoss: 0.272332\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [1280/10000 (13%)]\tLoss: 0.478208\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [1920/10000 (19%)]\tLoss: 0.286509\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [2560/10000 (25%)]\tLoss: 0.208677\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [3200/10000 (32%)]\tLoss: 0.252981\tAccuracy: 90.625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [3840/10000 (38%)]\tLoss: 0.327071\tAccuracy: 93.75\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [4480/10000 (45%)]\tLoss: 0.439867\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [5120/10000 (51%)]\tLoss: 0.501683\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [5760/10000 (57%)]\tLoss: 0.374832\tAccuracy: 87.5\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [6400/10000 (64%)]\tLoss: 0.481234\tAccuracy: 85.9375\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [7040/10000 (70%)]\tLoss: 0.282980\tAccuracy: 89.0625\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [7680/10000 (76%)]\tLoss: 0.187644\tAccuracy: 96.875\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [8320/10000 (83%)]\tLoss: 0.154393\tAccuracy: 100.0\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [8960/10000 (89%)]\tLoss: 0.296240\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:[Worker0] Validation Epoch: 5 [9600/10000 (96%)]\tLoss: 0.354034\tAccuracy: 92.1875\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Validation\n",
      "[1,0]<stdout>:Epoch 5/5\n",
      "[1,0]<stdout>:Loss: 0.3369 Acc: 91.0500\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Network was found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.register_model(model_name=\"mnist-linear-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 2(MNIST-torchvision)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change modulename\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "modulename = \"mnist-CNN\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./net/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $net_filename\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change dataset name\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "dataset_name = \"MNIST2\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./dataset/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "class DatasetLoader:    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        thispath = os.path.dirname(os.path.abspath(__file__))\n",
    "        data_dir = os.path.join(thispath,\"MNIST2\")\n",
    "        mnist_transform=transforms.Compose([\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        train_dataset = datasets.MNIST(data_dir, transform=mnist_transform, train=True,  download=True)        \n",
    "        test_dataset  = datasets.MNIST(data_dir, transform=mnist_transform, train=False, download=True)\n",
    "        \n",
    "        ### train_ds and valid_ds MUST BE TensorDataset(or ImageFolder or Torch Dataset Format)\n",
    "        self.train_dataset = train_dataset\n",
    "        self.valid_dataset = test_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        ####################################################\n",
    "    \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':64,\n",
    "    'test-batch-size':128,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    #'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    #'loss':'cross_entropy',\n",
    "    'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'validation': True,\n",
    "    'debug': True    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TorchEstimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.monitor(timeout=10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.register_model(model_name=\"mnist-good-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = estimator.get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction by cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import torch\n",
    "\n",
    "data_dir = \"./dataset/MNIST-TEST\"\n",
    "mnist_transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))])\n",
    "test_dataset  = datasets.MNIST(data_dir, transform=mnist_transform, train=False, download=True)\n",
    "batch_size = 32\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('0','1','2','3','4','5','6','7','8','9')\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(testloader):\n",
    "        images, labels = data        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)        \n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(data)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %2s : %3d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if you only want to use trained model and predict, let's do this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aistudio.torchestimator import TorchEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':64,\n",
    "    'test-batch-size':128,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    #'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    #'loss':'cross_entropy',\n",
    "    'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'validation': True,\n",
    "    'debug': True    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_name = \"mnist-good-model\"\n",
    "estimator = TorchEstimator(model_name=trained_model_name,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"MNIST2\"\n",
    "estimator.predict(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 3(CIFAR10)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED - Feel free to change\n",
    "modulename = \"CIFAR10-CNN\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./net/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $net_filename\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change dataset name\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "dataset_name = \"CIFAR10\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./dataset/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "\n",
    "class DatasetLoader:    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        thispath = os.path.dirname(os.path.abspath(__file__))\n",
    "        data_dir = os.path.join(thispath,\"CIFAR10\")\n",
    "        trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True,\n",
    "                                                download=True, transform=transform)\n",
    "        testset = torchvision.datasets.CIFAR10(root=data_dir, train=False,\n",
    "                                               download=True, transform=transform)\n",
    "        self.train_dataset = trainset\n",
    "        self.valid_dataset = testset\n",
    "        self.test_dataset = testset\n",
    "        ####################################################\n",
    "        \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':32,\n",
    "    'test-batch-size':64,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.9,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    #'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    'loss':'cross_entropy',\n",
    "    #'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'debug': True,\n",
    "    #\"validation\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TorchEstimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 4(hymenoptera)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED - Feel free to change\n",
    "modulename = \"resnet18\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./net/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $net_filename\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):        \n",
    "        super(Net, self).__init__()        \n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        # Here the size of each output sample is set to 2.\n",
    "        # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "        self.model.fc = nn.Linear(num_ftrs, 2)        \n",
    "        #self.add_module(\"resnet18\", self.model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change dataset name\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "dataset_name = \"hymenoptera\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./dataset/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "\n",
    "class DatasetLoader:    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        # Just normalization for validation\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "        }\n",
    "        thispath = os.path.dirname(os.path.abspath(__file__))\n",
    "        data_dir = os.path.join(thispath,\"hymenoptera_data\")        \n",
    "        image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                                  data_transforms[x])\n",
    "                          for x in ['train', 'val']}\n",
    "        self.train_dataset = image_datasets['train']\n",
    "        self.valid_dataset = image_datasets['val']\n",
    "        ####################################################\n",
    "        \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'dataset/hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':25,\n",
    "    'batch-size':4,\n",
    "    'test-batch-size':8,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    #'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    'loss':'cross_entropy',\n",
    "    #'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'validation': True,\n",
    "    'debug': True    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TorchEstimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 5(MNIST-.csv, .png)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED - Feel free to change\n",
    "modulename = \"mnist-csv\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./net/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $net_filename\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change dataset name\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "dataset_name = \"mnist-images\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./dataset/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "class DatasetLoader:    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        # Just normalization for validation        \n",
    "        mnist_transform=transforms.Compose([transforms.Grayscale(),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        thispath = os.path.dirname(os.path.abspath(__file__))\n",
    "        data_dir = os.path.join(thispath,\"image-datasets\",\"mnist\",\"images\")\n",
    "        image_dataset = torchvision.datasets.ImageFolder(data_dir,mnist_transform)\n",
    "        \n",
    "        self.train_dataset = image_dataset\n",
    "        ####################################################\n",
    "        \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':32,\n",
    "    'test-batch-size':64,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    'no-cuda':True,\n",
    "    'nprocs':1,\n",
    "    #'loss':'cross_entropy',\n",
    "    'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'debug': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TorchEstimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "download_root = 'train-data'\n",
    "mnist_transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                           ,transforms.Normalize((0.1307,), (0.3081,))\n",
    "                           ])\n",
    "train_dataset  = datasets.MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "input_data_torch = train_dataset.data\n",
    "input_data_torch = torch.div(input_data_torch,255.)\n",
    "input_data_torch = torch.add(input_data_torch,-0.1307)\n",
    "input_data_torch = torch.div(input_data_torch,0.3081)\n",
    "input_data_torch = input_data_torch.unsqueeze(1)\n",
    "input_labels_torch = train_dataset.targets\n",
    "# Convert Tensor to Numpy\n",
    "input_data = input_data_torch.numpy()\n",
    "input_labels = input_labels_torch.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Check data type and shape\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(input_data))\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-info\">\n",
    "    Set Script Parameters\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':64,\n",
    "    'test-batch-size':128,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    #'no-cuda': True, # True is dummy value, value is always True\n",
    "    'nprocs':1,\n",
    "    #'loss':'cross_entropy',\n",
    "    'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'debug': True # True is dummy value, value is always True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1 (with model name in the aistudio service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TorchEstimator(model_name=\"model-1\",script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(input_data,input_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile './estimator3_test.py'\n",
    "\n",
    "# from aistudio.estimator3 import Estimator\n",
    "# import torch\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "# download_root = 'train-data'\n",
    "# mnist_transform=transforms.Compose([\n",
    "#                            transforms.ToTensor()\n",
    "#                            ,transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                            ])\n",
    "# train_dataset  = datasets.MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "# input_data_torch = train_dataset.data\n",
    "# input_data_torch = torch.div(input_data_torch,255.)\n",
    "# input_data_torch = torch.add(input_data_torch,-0.1307)\n",
    "# input_data_torch = torch.div(input_data_torch,0.3081)\n",
    "# input_data_torch = input_data_torch.unsqueeze(1)\n",
    "# input_labels_torch = train_dataset.targets\n",
    "# # Convert Tensor to Numpy\n",
    "# input_data = input_data_torch.numpy()\n",
    "# input_labels = input_labels_torch.numpy()\n",
    "# script_params = {\n",
    "#     'epochs':5,\n",
    "#     'batch-size':64,\n",
    "#     'test-batch-size':128,\n",
    "#     'lr':0.01,\n",
    "#     'momentum':0.5,\n",
    "#     'seed':42,\n",
    "#     'log-interval':10,\n",
    "#     'no-cuda':False,\n",
    "#     'nprocs':1,\n",
    "#     'loss':'cross_entropy',\n",
    "#     'optimizer':'SGD'\n",
    "# }\n",
    "# estimator = Estimator(model_name=\"model-1\",script_params=script_params)\n",
    "# estimator.fit(input_data,input_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
