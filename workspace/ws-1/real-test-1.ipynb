{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Estimator API Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aistudio.torchestimator import TorchEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'aistudio.torchestimator.TorchEstimator'>\n"
     ]
    }
   ],
   "source": [
    "print(TorchEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/sky/dev/aistudio/workspace/ws-1', '/home/sky/anaconda3/envs/ai/lib/python37.zip', '/home/sky/anaconda3/envs/ai/lib/python3.7', '/home/sky/anaconda3/envs/ai/lib/python3.7/lib-dynload', '', '/home/sky/anaconda3/envs/ai/lib/python3.7/site-packages', '/home/sky/tmp/jupyterlab-git', '/home/sky/anaconda3/envs/ai/lib/python3.7/site-packages/IPython/extensions', '/home/sky/.ipython', '../../']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../aistudio/torchestimator.py\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getfile(TorchEstimator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Scenario2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 1(MNIST-deeplearning.net)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change modulename\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "modulename = \"mnist-linear\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./nets/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $net_filename\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name(USER-DEFINED) - Feel free to change\n",
    "dataset_name = \"MNIST\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./datasets/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch\n",
    "import os\n",
    "\n",
    "class DatasetLoader:\n",
    "    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        \n",
    "        DATA_PATH = Path(\"datasets\")\n",
    "        PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "        PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        URL = \"http://deeplearning.net/data/mnist/\"\n",
    "        FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "        if not (PATH / FILENAME).exists():\n",
    "                content = requests.get(URL + FILENAME).content\n",
    "                (PATH / FILENAME).open(\"wb\").write(content)\n",
    "\n",
    "        with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "                ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")       \n",
    "\n",
    "        x_train, y_train, x_valid, y_valid = map(\n",
    "            torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    "        )\n",
    "        ### train_ds and valid_ds MUST BE TensorDataset(or ImageFolder or Torch Dataset Format)\n",
    "        self.train_dataset = TensorDataset(x_train, y_train)\n",
    "        self.valid_dataset = TensorDataset(x_valid, y_valid)\n",
    "        ####################################################\n",
    "        \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':64,\n",
    "    'test-batch-size':128,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    'loss':'cross_entropy',\n",
    "    #'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'validation': True,\n",
    "    'debug': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TorchEstimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.register_model(model_name=\"mnist-linear-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 2(MNIST-torchvision)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change modulename\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "modulename = \"mnist-CNN\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./nets/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $net_filename\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change dataset name\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "dataset_name = \"MNIST2\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./datasets/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "class DatasetLoader:    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        thispath = os.path.dirname(os.path.abspath(__file__))\n",
    "        data_dir = os.path.join(thispath,\"MNIST2\")\n",
    "        mnist_transform=transforms.Compose([\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        train_dataset = datasets.MNIST(data_dir, transform=mnist_transform, train=True,  download=True)        \n",
    "        test_dataset  = datasets.MNIST(data_dir, transform=mnist_transform, train=False, download=True)\n",
    "        \n",
    "        ### train_ds and valid_ds MUST BE TensorDataset(or ImageFolder or Torch Dataset Format)\n",
    "        self.train_dataset = train_dataset\n",
    "        self.valid_dataset = test_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        ####################################################\n",
    "    \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':64,\n",
    "    'test-batch-size':128,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    #'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    #'loss':'cross_entropy',\n",
    "    'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'validation': True,\n",
    "    'debug': True    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TorchEstimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.register_model(model_name=\"mnist-good-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = estimator.get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction by cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import torch\n",
    "\n",
    "data_dir = \"./datasets/MNIST-TEST\"\n",
    "mnist_transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))])\n",
    "test_dataset  = datasets.MNIST(data_dir, transform=mnist_transform, train=False, download=True)\n",
    "batch_size = 32\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('0','1','2','3','4','5','6','7','8','9')\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(testloader):\n",
    "        images, labels = data        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)        \n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(data)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %2s : %3d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if you only want to use trained model and predict, let's do this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aistudio.torchestimator import TorchEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':64,\n",
    "    'test-batch-size':128,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    #'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    #'loss':'cross_entropy',\n",
    "    'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'validation': True,\n",
    "    'debug': True    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--epochs', '5', '--batch-size', '64', '--test-batch-size', '128', '--lr', '0.01', '--momentum', '0.5', '--seed', '42', '--log-interval', '10', '--nprocs', '1', '--loss', 'nll_loss', '--optimizer', 'SGD', '--validation', '--debug', '--model-path', '/home/sky/dev/aistudio/workspace/ws-1/models/mnist-good-model']\n"
     ]
    }
   ],
   "source": [
    "trained_model_name = \"mnist-good-model\"\n",
    "estimator = TorchEstimator(model_name=trained_model_name,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Requested to Portal.\n",
      "[1,0]<stdout>:Namespace(batch_size=64, dataset_loader='MNIST2', debug=True, epochs=5, log_interval=10, loss='nll_loss', lr=0.01, model_path='/home/sky/dev/aistudio/workspace/ws-1/models/mnist-good-model', momentum=0.5, net_name=None, no_cuda=False, nprocs=1, optimizer='SGD', prediction=True, seed=42, test_batch_size=128, use_adasum=False, validation=True)\n",
      "[1,0]<stdout>:Arguments Parsing Finished.\n",
      "[1,0]<stdout>:CUDA Supported!\n",
      "[1,0]<stdout>:Model path was found.\n",
      "[1,0]<stdout>:Model's state_dict:\n",
      "[1,0]<stdout>:conv1.weight \t torch.Size([10, 1, 5, 5])\n",
      "[1,0]<stdout>:conv1.bias \t torch.Size([10])\n",
      "[1,0]<stdout>:conv2.weight \t torch.Size([20, 10, 5, 5])\n",
      "[1,0]<stdout>:conv2.bias \t torch.Size([20])\n",
      "[1,0]<stdout>:fc1.weight \t torch.Size([50, 320])\n",
      "[1,0]<stdout>:fc1.bias \t torch.Size([50])\n",
      "[1,0]<stdout>:fc2.weight \t torch.Size([10, 50])\n",
      "[1,0]<stdout>:fc2.bias \t torch.Size([10])\n",
      "[1,0]<stdout>:Optimizer's state_dict:\n",
      "[1,0]<stdout>:state \t {}\n",
      "[1,0]<stdout>:param_groups \t [{'lr': 0.009999999776482582, 'momentum': 0.5, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139632708342960, 139632708343040, 139632708343120, 139632708343200, 139632708343280, 139632708343360, 139632708343440, 139632708343520]}]\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [0/10000 (0%)]\tLoss: 0.032317\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [640/10000 (6%)]\tLoss: 0.052951\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [1280/10000 (13%)]\tLoss: 0.178275\tAccuracy: 93.75\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [1920/10000 (19%)]\tLoss: 0.020925\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [2560/10000 (25%)]\tLoss: 0.039535\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [3200/10000 (32%)]\tLoss: 0.029224\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [3840/10000 (38%)]\tLoss: 0.084160\tAccuracy: 93.75\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [4480/10000 (45%)]\tLoss: 0.063566\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [5120/10000 (51%)]\tLoss: 0.011201\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [5760/10000 (57%)]\tLoss: 0.056337\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [6400/10000 (64%)]\tLoss: 0.114686\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [7040/10000 (70%)]\tLoss: 0.052775\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [7680/10000 (76%)]\tLoss: 0.087943\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [8320/10000 (83%)]\tLoss: 0.047659\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [8960/10000 (89%)]\tLoss: 0.015892\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 1 [9600/10000 (96%)]\tLoss: 0.130328\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Prediction\n",
      "[1,0]<stdout>:Epoch 1/5\n",
      "[1,0]<stdout>:Loss: 0.0802 Acc: 97.5000\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [0/10000 (0%)]\tLoss: 0.065842\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [640/10000 (6%)]\tLoss: 0.214883\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [1280/10000 (13%)]\tLoss: 0.038266\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [1920/10000 (19%)]\tLoss: 0.015165\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [2560/10000 (25%)]\tLoss: 0.098834\tAccuracy: 93.75\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [3200/10000 (32%)]\tLoss: 0.108712\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [3840/10000 (38%)]\tLoss: 0.099550\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [4480/10000 (45%)]\tLoss: 0.110762\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [5120/10000 (51%)]\tLoss: 0.090617\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [5760/10000 (57%)]\tLoss: 0.026170\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [6400/10000 (64%)]\tLoss: 0.139153\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [7040/10000 (70%)]\tLoss: 0.055481\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [7680/10000 (76%)]\tLoss: 0.042139\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [8320/10000 (83%)]\tLoss: 0.076841\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [8960/10000 (89%)]\tLoss: 0.036452\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 2 [9600/10000 (96%)]\tLoss: 0.063726\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Prediction\n",
      "[1,0]<stdout>:Epoch 2/5\n",
      "[1,0]<stdout>:Loss: 0.0802 Acc: 97.5000\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [0/10000 (0%)]\tLoss: 0.025089\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [640/10000 (6%)]\tLoss: 0.019242\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [1280/10000 (13%)]\tLoss: 0.041994\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [1920/10000 (19%)]\tLoss: 0.128163\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [2560/10000 (25%)]\tLoss: 0.037051\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [3200/10000 (32%)]\tLoss: 0.233397\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [3840/10000 (38%)]\tLoss: 0.073563\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [4480/10000 (45%)]\tLoss: 0.023084\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [5120/10000 (51%)]\tLoss: 0.037053\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [5760/10000 (57%)]\tLoss: 0.027791\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [6400/10000 (64%)]\tLoss: 0.088884\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [7040/10000 (70%)]\tLoss: 0.045172\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [7680/10000 (76%)]\tLoss: 0.062011\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [8320/10000 (83%)]\tLoss: 0.102747\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [8960/10000 (89%)]\tLoss: 0.071366\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 3 [9600/10000 (96%)]\tLoss: 0.056628\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Prediction\n",
      "[1,0]<stdout>:Epoch 3/5\n",
      "[1,0]<stdout>:Loss: 0.0802 Acc: 97.5000\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [0/10000 (0%)]\tLoss: 0.031895\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [640/10000 (6%)]\tLoss: 0.110820\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [1280/10000 (13%)]\tLoss: 0.020790\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [1920/10000 (19%)]\tLoss: 0.023470\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [2560/10000 (25%)]\tLoss: 0.021080\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [3200/10000 (32%)]\tLoss: 0.010651\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [3840/10000 (38%)]\tLoss: 0.061766\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [4480/10000 (45%)]\tLoss: 0.318826\tAccuracy: 93.75\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [5120/10000 (51%)]\tLoss: 0.012229\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [5760/10000 (57%)]\tLoss: 0.045596\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [6400/10000 (64%)]\tLoss: 0.014129\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [7040/10000 (70%)]\tLoss: 0.137416\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [7680/10000 (76%)]\tLoss: 0.058064\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [8320/10000 (83%)]\tLoss: 0.116216\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [8960/10000 (89%)]\tLoss: 0.032155\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 4 [9600/10000 (96%)]\tLoss: 0.147083\tAccuracy: 96.875\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Prediction\n",
      "[1,0]<stdout>:Epoch 4/5\n",
      "[1,0]<stdout>:Loss: 0.0802 Acc: 97.5000\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [0/10000 (0%)]\tLoss: 0.096816\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [640/10000 (6%)]\tLoss: 0.178110\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [1280/10000 (13%)]\tLoss: 0.124096\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [1920/10000 (19%)]\tLoss: 0.165930\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [2560/10000 (25%)]\tLoss: 0.016275\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [3200/10000 (32%)]\tLoss: 0.058808\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [3840/10000 (38%)]\tLoss: 0.132657\tAccuracy: 93.75\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [4480/10000 (45%)]\tLoss: 0.082909\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [5120/10000 (51%)]\tLoss: 0.047943\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [5760/10000 (57%)]\tLoss: 0.211964\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [6400/10000 (64%)]\tLoss: 0.020754\tAccuracy: 100.0\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [7040/10000 (70%)]\tLoss: 0.046370\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [7680/10000 (76%)]\tLoss: 0.068122\tAccuracy: 96.875\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [8320/10000 (83%)]\tLoss: 0.032454\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [8960/10000 (89%)]\tLoss: 0.167908\tAccuracy: 95.3125\n",
      "[1,0]<stdout>:Prediction Epoch: 5 [9600/10000 (96%)]\tLoss: 0.038497\tAccuracy: 98.4375\n",
      "[1,0]<stdout>:----------\n",
      "[1,0]<stdout>:Phase: Prediction\n",
      "[1,0]<stdout>:Epoch 5/5\n",
      "[1,0]<stdout>:Loss: 0.0802 Acc: 97.5000\n",
      "[1,0]<stdout>:----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"MNIST2\"\n",
    "estimator.predict(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 3(CIFAR10)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED - Feel free to change\n",
    "modulename = \"CIFAR10-CNN\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./nets/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $net_filename\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change dataset name\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "dataset_name = \"CIFAR10\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./datasets/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "\n",
    "class DatasetLoader:    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        thispath = os.path.dirname(os.path.abspath(__file__))\n",
    "        data_dir = os.path.join(thispath,\"CIFAR10\")\n",
    "        trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True,\n",
    "                                                download=True, transform=transform)\n",
    "        testset = torchvision.datasets.CIFAR10(root=data_dir, train=False,\n",
    "                                               download=True, transform=transform)\n",
    "        self.train_dataset = trainset\n",
    "        self.valid_dataset = testset\n",
    "        self.test_dataset = testset\n",
    "        ####################################################\n",
    "        \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':32,\n",
    "    'test-batch-size':64,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.9,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    #'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    'loss':'cross_entropy',\n",
    "    #'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'debug': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 4(hymenoptera)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED - Feel free to change\n",
    "modulename = \"resnet18\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./nets/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $net_filename\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):        \n",
    "        super(Net, self).__init__()        \n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        # Here the size of each output sample is set to 2.\n",
    "        # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "        self.model.fc = nn.Linear(num_ftrs, 2)        \n",
    "        #self.add_module(\"resnet18\", self.model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change dataset name\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "dataset_name = \"hymenoptera\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./datasets/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "\n",
    "class DatasetLoader:    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        # Just normalization for validation\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "        }\n",
    "        thispath = os.path.dirname(os.path.abspath(__file__))\n",
    "        data_dir = os.path.join(thispath,\"hymenoptera_data\")        \n",
    "        image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                                  data_transforms[x])\n",
    "                          for x in ['train', 'val']}\n",
    "        self.train_dataset = image_datasets['train']\n",
    "        self.valid_dataset = image_datasets['val']\n",
    "        ####################################################\n",
    "        \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'datasets/hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':25,\n",
    "    'batch-size':4,\n",
    "    'test-batch-size':8,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    #'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    'loss':'cross_entropy',\n",
    "    #'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'validation': True,\n",
    "    'debug': True    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1>Example 5(MNIST-.csv, .png)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED - Feel free to change\n",
    "modulename = \"mnist-csv\"\n",
    "######### DO NOT CHANGE #########\n",
    "net_filename = modulename + \".py\"\n",
    "net_filename = \"./nets/\" + net_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Do not change code below at Line 1 to 3 </p>\n",
    "    <p>Do not change class name <b>'Net'</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $net_filename\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Feel free to change dataset name\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED\n",
    "dataset_name = \"mnist-images\"\n",
    "######### DO NOT CHANGE #########\n",
    "dataset_filename = dataset_name + \".py\"\n",
    "dataset_filename = \"./datasets/\" + dataset_filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dataset_filename\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "class DatasetLoader:    \n",
    "    def __init__(self):\n",
    "        ########## WRITE DATASET LOADER CODE HERE ##########\n",
    "        # Just normalization for validation        \n",
    "        mnist_transform=transforms.Compose([transforms.Grayscale(),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        thispath = os.path.dirname(os.path.abspath(__file__))\n",
    "        data_dir = os.path.join(thispath,\"image-datasets\",\"mnist\",\"images\")\n",
    "        image_dataset = torchvision.datasets.ImageFolder(data_dir,mnist_transform)\n",
    "        \n",
    "        self.train_dataset = image_dataset\n",
    "        ####################################################\n",
    "        \n",
    "    def get_train_dataset(self, validation=True):        \n",
    "        if validation is True:\n",
    "            return self.train_dataset, self.valid_dataset\n",
    "        else:\n",
    "            return self.train_dataset\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':32,\n",
    "    'test-batch-size':64,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    'no-cuda':True,\n",
    "    'nprocs':1,\n",
    "    #'loss':'cross_entropy',\n",
    "    'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'debug': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(dataset_loader=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "download_root = 'train-data'\n",
    "mnist_transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                           ,transforms.Normalize((0.1307,), (0.3081,))\n",
    "                           ])\n",
    "train_dataset  = datasets.MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "input_data_torch = train_dataset.data\n",
    "input_data_torch = torch.div(input_data_torch,255.)\n",
    "input_data_torch = torch.add(input_data_torch,-0.1307)\n",
    "input_data_torch = torch.div(input_data_torch,0.3081)\n",
    "input_data_torch = input_data_torch.unsqueeze(1)\n",
    "input_labels_torch = train_dataset.targets\n",
    "# Convert Tensor to Numpy\n",
    "input_data = input_data_torch.numpy()\n",
    "input_labels = input_labels_torch.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Check data type and shape\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(input_data))\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-info\">\n",
    "    Set Script Parameters\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':64,\n",
    "    'test-batch-size':128,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    #'no-cuda': True, # True is dummy value, value is always True\n",
    "    'nprocs':1,\n",
    "    #'loss':'cross_entropy',\n",
    "    'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'debug': True # True is dummy value, value is always True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1 (with model name in the aistudio service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(model_name=\"model-1\",script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(input_data,input_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile './estimator3_test.py'\n",
    "\n",
    "# from aistudio.estimator3 import Estimator\n",
    "# import torch\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "# download_root = 'train-data'\n",
    "# mnist_transform=transforms.Compose([\n",
    "#                            transforms.ToTensor()\n",
    "#                            ,transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                            ])\n",
    "# train_dataset  = datasets.MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "# input_data_torch = train_dataset.data\n",
    "# input_data_torch = torch.div(input_data_torch,255.)\n",
    "# input_data_torch = torch.add(input_data_torch,-0.1307)\n",
    "# input_data_torch = torch.div(input_data_torch,0.3081)\n",
    "# input_data_torch = input_data_torch.unsqueeze(1)\n",
    "# input_labels_torch = train_dataset.targets\n",
    "# # Convert Tensor to Numpy\n",
    "# input_data = input_data_torch.numpy()\n",
    "# input_labels = input_labels_torch.numpy()\n",
    "# script_params = {\n",
    "#     'epochs':5,\n",
    "#     'batch-size':64,\n",
    "#     'test-batch-size':128,\n",
    "#     'lr':0.01,\n",
    "#     'momentum':0.5,\n",
    "#     'seed':42,\n",
    "#     'log-interval':10,\n",
    "#     'no-cuda':False,\n",
    "#     'nprocs':1,\n",
    "#     'loss':'cross_entropy',\n",
    "#     'optimizer':'SGD'\n",
    "# }\n",
    "# estimator = Estimator(model_name=\"model-1\",script_params=script_params)\n",
    "# estimator.fit(input_data,input_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 2 (with model object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make network and load model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"./mnist_net.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(model_name=\"model-2\",script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(input_data,input_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-DEFINED - Feel free to change\n",
    "modulename = \"torchnet\"\n",
    "######### DO NOT CHANGE #########\n",
    "filename = modulename + \".py\"\n",
    "filename = \"./nets/\" + filename\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Do not change code below at Line 1 to 3\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $filename\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    'epochs':5,\n",
    "    'batch-size':64,\n",
    "    'test-batch-size':128,\n",
    "    'lr':0.01,\n",
    "    'momentum':0.5,\n",
    "    'seed':42,\n",
    "    'log-interval':10,\n",
    "    'no-cuda':False,\n",
    "    'nprocs':1,\n",
    "    #'loss':'cross_entropy',\n",
    "    'loss':'nll_loss',\n",
    "    'optimizer':'SGD',\n",
    "    'debug': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(net_name=modulename,script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(input_data,input_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
