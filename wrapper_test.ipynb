{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Estimator to run a script to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aistudio.pytorch import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    '--batch-size': 64,\n",
    "    '--test-batch-size': 128,\n",
    "    '--lr': 0.5,\n",
    "    '--epochs': 10\n",
    "    #,'--nprocs': 4\n",
    "}\n",
    "estimator = PyTorch(script=\"train.py\",script_params=script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator with Model File(.onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator needs test-batch-size, test dataloader and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aistudio.estimator import Estimator\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "script_params = {\n",
    "    '--test-batch-size': 128\n",
    "}\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "download_root = 'test-data'\n",
    "mnist_transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                           ,transforms.Normalize((0.1307,), (0.3081,))\n",
    "                           ])\n",
    "test_dataset  = datasets.MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
    "# Data Preperation\n",
    "input_data = test_dataset.data\n",
    "input_data = torch.add(input_data,-0.1307)\n",
    "input_data = torch.div(input_data,0.3081)\n",
    "input_data = input_data.unsqueeze(1)\n",
    "input_labels = test_dataset.targets\n",
    "\n",
    "estimator = Estimator(use_model=True,model_path=\"mnist_net.onnx\",script_params=script_params)\n",
    "estimator.validate(input_data, input_labels, loss=\"nll_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator with Model File(.pth)\n",
    "\n",
    "Estimator with PyTorch Model File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aistudio.estimator import Estimator\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# define script parameters\n",
    "script_params = {\n",
    "    '--test-batch-size': 128\n",
    "}\n",
    "# Data Preparation and Pre-Processing\n",
    "download_root = 'test-data'\n",
    "mnist_transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                           ,transforms.Normalize((0.1307,), (0.3081,))\n",
    "                           ])\n",
    "test_dataset  = datasets.MNIST(download_root, transform=mnist_transform, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing for testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input_data = test_dataset.data\n",
    "input_data = torch.add(input_data,-0.1307)\n",
    "input_data = torch.div(input_data,0.3081)\n",
    "input_data = input_data.unsqueeze(1)\n",
    "input_labels = test_dataset.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate(Test) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Model was Loaded.\n",
      "mnist_net .pth\n",
      "Validation by PyTorch Model.\n",
      "Loss: 8.533471\tAccuracy: 98.39\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "estimator = Estimator(use_model=True,model_path=\"mnist_net.pth\",network=net,script_params=script_params)\n",
    "estimator.validate(input_data, input_labels, loss=\"nll_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation and Preprocessing for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-748cd6ee44d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_dataset\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.1307\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.3081\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "download_root = 'train-data'\n",
    "mnist_transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                           ,transforms.Normalize((0.1307,), (0.3081,))\n",
    "                           ])\n",
    "train_dataset  = datasets.MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "input_data = train_dataset.data\n",
    "input_data = torch.add(input_data,-0.1307)\n",
    "input_data = torch.div(input_data,0.3081)\n",
    "input_data = input_data.unsqueeze(1)\n",
    "input_labels = train_dataset.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to use only model file(it couldn't update weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Model was Loaded.\n",
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([10, 1, 5, 5])\n",
      "conv1.bias \t torch.Size([10])\n",
      "conv2.weight \t torch.Size([20, 10, 5, 5])\n",
      "conv2.bias \t torch.Size([20])\n",
      "fc1.weight \t torch.Size([50, 320])\n",
      "fc1.bias \t torch.Size([50])\n",
      "fc2.weight \t torch.Size([10, 50])\n",
      "fc2.bias \t torch.Size([10])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.05, 'momentum': 0.5, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139750923564288, 139750923580512, 139750923581632, 139750923582192, 139750923580752, 139750923518352, 139753063290272, 139753063334928]}]\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 65.416222\tAccuracy: 15.625\n",
      "Train Epoch: 1 [640/10000 (6%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: nan\tAccuracy: 6.25\n",
      "Train Epoch: 1 [1920/10000 (19%)]\tLoss: nan\tAccuracy: 4.6875\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 1 [3200/10000 (32%)]\tLoss: nan\tAccuracy: 10.9375\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: nan\tAccuracy: 12.5\n",
      "Train Epoch: 1 [4480/10000 (45%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: nan\tAccuracy: 10.9375\n",
      "Train Epoch: 1 [5760/10000 (57%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 1 [6400/10000 (64%)]\tLoss: nan\tAccuracy: 14.0625\n",
      "Train Epoch: 1 [7040/10000 (70%)]\tLoss: nan\tAccuracy: 9.375\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: nan\tAccuracy: 14.0625\n",
      "Train Epoch: 1 [8320/10000 (83%)]\tLoss: nan\tAccuracy: 14.0625\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: nan\tAccuracy: 10.9375\n",
      "Train Epoch: 1 [9600/10000 (96%)]\tLoss: nan\tAccuracy: 14.0625\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: nan\tAccuracy: 9.375\n",
      "Train Epoch: 2 [640/10000 (6%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: nan\tAccuracy: 6.25\n",
      "Train Epoch: 2 [1920/10000 (19%)]\tLoss: nan\tAccuracy: 4.6875\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 2 [3200/10000 (32%)]\tLoss: nan\tAccuracy: 10.9375\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: nan\tAccuracy: 12.5\n",
      "Train Epoch: 2 [4480/10000 (45%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: nan\tAccuracy: 10.9375\n",
      "Train Epoch: 2 [5760/10000 (57%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 2 [6400/10000 (64%)]\tLoss: nan\tAccuracy: 14.0625\n",
      "Train Epoch: 2 [7040/10000 (70%)]\tLoss: nan\tAccuracy: 9.375\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: nan\tAccuracy: 14.0625\n",
      "Train Epoch: 2 [8320/10000 (83%)]\tLoss: nan\tAccuracy: 14.0625\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: nan\tAccuracy: 10.9375\n",
      "Train Epoch: 2 [9600/10000 (96%)]\tLoss: nan\tAccuracy: 14.0625\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: nan\tAccuracy: 9.375\n",
      "Train Epoch: 3 [640/10000 (6%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: nan\tAccuracy: 6.25\n",
      "Train Epoch: 3 [1920/10000 (19%)]\tLoss: nan\tAccuracy: 4.6875\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 3 [3200/10000 (32%)]\tLoss: nan\tAccuracy: 10.9375\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: nan\tAccuracy: 12.5\n",
      "Train Epoch: 3 [4480/10000 (45%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: nan\tAccuracy: 10.9375\n",
      "Train Epoch: 3 [5760/10000 (57%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 3 [6400/10000 (64%)]\tLoss: nan\tAccuracy: 14.0625\n",
      "Train Epoch: 3 [7040/10000 (70%)]\tLoss: nan\tAccuracy: 9.375\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: nan\tAccuracy: 14.0625\n",
      "Train Epoch: 3 [8320/10000 (83%)]\tLoss: nan\tAccuracy: 14.0625\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: nan\tAccuracy: 10.9375\n",
      "Train Epoch: 3 [9600/10000 (96%)]\tLoss: nan\tAccuracy: 14.0625\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: nan\tAccuracy: 9.375\n",
      "Train Epoch: 4 [640/10000 (6%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: nan\tAccuracy: 6.25\n",
      "Train Epoch: 4 [1920/10000 (19%)]\tLoss: nan\tAccuracy: 4.6875\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 4 [3200/10000 (32%)]\tLoss: nan\tAccuracy: 10.9375\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: nan\tAccuracy: 12.5\n",
      "Train Epoch: 4 [4480/10000 (45%)]\tLoss: nan\tAccuracy: 7.8125\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: nan\tAccuracy: 10.9375\n",
      "Train Epoch: 4 [5760/10000 (57%)]\tLoss: nan\tAccuracy: 7.8125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6d05b90ba113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mnist_init_net.pt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscript_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscript_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nll_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SGD\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/aiplatform-test/aistudio/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, input_data, input_labels, loss, opt)\u001b[0m\n\u001b[1;32m    228\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "script_params = {\n",
    "    '--epochs': 5,\n",
    "    '--batch-size': 64,\n",
    "    '--test-batch-size': 128,\n",
    "    '--lr': 0.05\n",
    "}\n",
    "\n",
    "net = Net()\n",
    "estimator = Estimator(use_model=True,model_path=\"mnist_init_net.pt\",network=net,script_params=script_params,debug=True)\n",
    "estimator.fit(input_data, input_labels, loss=\"nll_loss\", opt=\"SGD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to use only model file with checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "script_params = {\n",
    "    '--epochs': 5,\n",
    "    '--batch-size': 64,\n",
    "    '--test-batch-size': 128,\n",
    "    '--lr': 0.05\n",
    "}\n",
    "\n",
    "net = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05)\n",
    "estimator = Estimator(use_model=True,model_path=\"mnist_init_net_checkpoint.pt\",network=net,use_optimizer=True,optimizer=optimizer,script_params=script_params,debug=True)\n",
    "estimator.fit(input_data, input_labels, loss=\"nll_loss\", opt=\"SGD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to use only model file with checkpoint and cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Supported!\n",
      "PyTorch Model was Loaded.\n",
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([10, 1, 5, 5])\n",
      "conv1.bias \t torch.Size([10])\n",
      "conv2.weight \t torch.Size([20, 10, 5, 5])\n",
      "conv2.bias \t torch.Size([20])\n",
      "fc1.weight \t torch.Size([50, 320])\n",
      "fc1.bias \t torch.Size([50])\n",
      "fc2.weight \t torch.Size([10, 50])\n",
      "fc2.bias \t torch.Size([10])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.0010000000474974513, 'momentum': 0.8999999761581421, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140667496647008, 140667496648448, 140665489182464, 140667562701680, 140665489243584, 140667562704160, 140667562704080, 140667562704320]}]\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 59.207573\tAccuracy: 15.625\n",
      "Train Epoch: 1 [640/10000 (6%)]\tLoss: 2.357342\tAccuracy: 17.1875\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 2.308648\tAccuracy: 10.9375\n",
      "Train Epoch: 1 [1920/10000 (19%)]\tLoss: 2.275275\tAccuracy: 7.8125\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 2.329717\tAccuracy: 14.0625\n",
      "Train Epoch: 1 [3200/10000 (32%)]\tLoss: 2.296793\tAccuracy: 12.5\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 2.232315\tAccuracy: 17.1875\n",
      "Train Epoch: 1 [4480/10000 (45%)]\tLoss: 2.257851\tAccuracy: 12.5\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 2.270700\tAccuracy: 14.0625\n",
      "Train Epoch: 1 [5760/10000 (57%)]\tLoss: 2.287441\tAccuracy: 14.0625\n",
      "Train Epoch: 1 [6400/10000 (64%)]\tLoss: 2.206477\tAccuracy: 14.0625\n",
      "Train Epoch: 1 [7040/10000 (70%)]\tLoss: 2.099210\tAccuracy: 23.4375\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 2.092037\tAccuracy: 23.4375\n",
      "Train Epoch: 1 [8320/10000 (83%)]\tLoss: 2.174932\tAccuracy: 20.3125\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 2.019626\tAccuracy: 26.5625\n",
      "Train Epoch: 1 [9600/10000 (96%)]\tLoss: 1.898058\tAccuracy: 34.375\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 1.997962\tAccuracy: 18.75\n",
      "Train Epoch: 2 [640/10000 (6%)]\tLoss: 2.011769\tAccuracy: 26.5625\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 1.868405\tAccuracy: 35.9375\n",
      "Train Epoch: 2 [1920/10000 (19%)]\tLoss: 1.774574\tAccuracy: 31.25\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 1.964304\tAccuracy: 34.375\n",
      "Train Epoch: 2 [3200/10000 (32%)]\tLoss: 1.799509\tAccuracy: 34.375\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 1.804636\tAccuracy: 32.8125\n",
      "Train Epoch: 2 [4480/10000 (45%)]\tLoss: 2.006011\tAccuracy: 26.5625\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 1.674291\tAccuracy: 35.9375\n",
      "Train Epoch: 2 [5760/10000 (57%)]\tLoss: 1.551665\tAccuracy: 39.0625\n",
      "Train Epoch: 2 [6400/10000 (64%)]\tLoss: 1.504241\tAccuracy: 51.5625\n",
      "Train Epoch: 2 [7040/10000 (70%)]\tLoss: 1.611643\tAccuracy: 40.625\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 1.506330\tAccuracy: 48.4375\n",
      "Train Epoch: 2 [8320/10000 (83%)]\tLoss: 1.392959\tAccuracy: 48.4375\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 1.733093\tAccuracy: 46.875\n",
      "Train Epoch: 2 [9600/10000 (96%)]\tLoss: 1.458147\tAccuracy: 46.875\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 1.615761\tAccuracy: 43.75\n",
      "Train Epoch: 3 [640/10000 (6%)]\tLoss: 1.608177\tAccuracy: 39.0625\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 1.685020\tAccuracy: 45.3125\n",
      "Train Epoch: 3 [1920/10000 (19%)]\tLoss: 1.352949\tAccuracy: 46.875\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 1.469550\tAccuracy: 51.5625\n",
      "Train Epoch: 3 [3200/10000 (32%)]\tLoss: 1.266631\tAccuracy: 50.0\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 1.556378\tAccuracy: 40.625\n",
      "Train Epoch: 3 [4480/10000 (45%)]\tLoss: 1.177490\tAccuracy: 56.25\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 1.125160\tAccuracy: 59.375\n",
      "Train Epoch: 3 [5760/10000 (57%)]\tLoss: 1.413880\tAccuracy: 43.75\n",
      "Train Epoch: 3 [6400/10000 (64%)]\tLoss: 1.497020\tAccuracy: 42.1875\n",
      "Train Epoch: 3 [7040/10000 (70%)]\tLoss: 1.482939\tAccuracy: 46.875\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 1.427995\tAccuracy: 39.0625\n",
      "Train Epoch: 3 [8320/10000 (83%)]\tLoss: 1.319920\tAccuracy: 57.8125\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 1.031463\tAccuracy: 60.9375\n",
      "Train Epoch: 3 [9600/10000 (96%)]\tLoss: 1.179039\tAccuracy: 51.5625\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 0.995846\tAccuracy: 67.1875\n",
      "Train Epoch: 4 [640/10000 (6%)]\tLoss: 1.333756\tAccuracy: 51.5625\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 1.270040\tAccuracy: 45.3125\n",
      "Train Epoch: 4 [1920/10000 (19%)]\tLoss: 1.353949\tAccuracy: 57.8125\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 1.206596\tAccuracy: 54.6875\n",
      "Train Epoch: 4 [3200/10000 (32%)]\tLoss: 1.415411\tAccuracy: 50.0\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 1.011849\tAccuracy: 65.625\n",
      "Train Epoch: 4 [4480/10000 (45%)]\tLoss: 1.377367\tAccuracy: 46.875\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 0.965393\tAccuracy: 68.75\n",
      "Train Epoch: 4 [5760/10000 (57%)]\tLoss: 1.286190\tAccuracy: 50.0\n",
      "Train Epoch: 4 [6400/10000 (64%)]\tLoss: 1.335919\tAccuracy: 56.25\n",
      "Train Epoch: 4 [7040/10000 (70%)]\tLoss: 1.329450\tAccuracy: 53.125\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 0.926481\tAccuracy: 67.1875\n",
      "Train Epoch: 4 [8320/10000 (83%)]\tLoss: 0.916438\tAccuracy: 62.5\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 1.029903\tAccuracy: 62.5\n",
      "Train Epoch: 4 [9600/10000 (96%)]\tLoss: 1.004928\tAccuracy: 60.9375\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 0.968190\tAccuracy: 64.0625\n",
      "Train Epoch: 5 [640/10000 (6%)]\tLoss: 1.344732\tAccuracy: 62.5\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 0.994274\tAccuracy: 62.5\n",
      "Train Epoch: 5 [1920/10000 (19%)]\tLoss: 1.399820\tAccuracy: 59.375\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 0.921132\tAccuracy: 70.3125\n",
      "Train Epoch: 5 [3200/10000 (32%)]\tLoss: 1.294798\tAccuracy: 57.8125\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 1.122046\tAccuracy: 60.9375\n",
      "Train Epoch: 5 [4480/10000 (45%)]\tLoss: 0.954940\tAccuracy: 62.5\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 1.033797\tAccuracy: 71.875\n",
      "Train Epoch: 5 [5760/10000 (57%)]\tLoss: 0.929736\tAccuracy: 59.375\n",
      "Train Epoch: 5 [6400/10000 (64%)]\tLoss: 1.001857\tAccuracy: 65.625\n",
      "Train Epoch: 5 [7040/10000 (70%)]\tLoss: 0.697746\tAccuracy: 71.875\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 1.040869\tAccuracy: 60.9375\n",
      "Train Epoch: 5 [8320/10000 (83%)]\tLoss: 0.804285\tAccuracy: 73.4375\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 1.049869\tAccuracy: 67.1875\n",
      "Train Epoch: 5 [9600/10000 (96%)]\tLoss: 0.857515\tAccuracy: 68.75\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "script_params = {\n",
    "    '--epochs': 5,\n",
    "    '--batch-size': 64,\n",
    "    '--test-batch-size': 128,\n",
    "    '--lr': 0.05\n",
    "}\n",
    "\n",
    "net = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05)\n",
    "estimator = Estimator(use_cuda=True,use_model=True,model_path=\"mnist_init_net_checkpoint.pt\",network=net,use_optimizer=True,optimizer=optimizer,script_params=script_params,debug=True)\n",
    "estimator.fit(input_data, input_labels, loss=\"nll_loss\", opt=\"SGD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Make Horovod Running Test Python File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./test_estimator_hvd.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile './test_estimator_hvd.py'\n",
    "\n",
    "from aistudio.estimator import Estimator\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "# import horovod.torch as hvd\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # define script parameters\n",
    "    script_params = {\n",
    "        '--test-batch-size': 128\n",
    "    }\n",
    "    # Data Preparation and Pre-Processing\n",
    "    download_root = 'train-data'\n",
    "    mnist_transform=transforms.Compose([\n",
    "                               transforms.ToTensor()\n",
    "                               ,transforms.Normalize((0.1307,), (0.3081,))\n",
    "                               ])\n",
    "    train_dataset  = datasets.MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "    input_data = train_dataset.data\n",
    "    input_data = torch.add(input_data,-0.1307)\n",
    "    input_data = torch.div(input_data,0.3081)\n",
    "    input_data = input_data.unsqueeze(1)\n",
    "    input_labels = train_dataset.targets\n",
    "\n",
    "    script_params = {\n",
    "        '--epochs': 5,\n",
    "        '--batch-size': 64,\n",
    "        '--test-batch-size': 128,\n",
    "        '--lr': 0.05\n",
    "    }\n",
    "    net = Net()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.05)\n",
    "    estimator = Estimator(use_cuda=True,use_model=True,model_path=\"mnist_init_net_checkpoint.pt\",network=net,use_optimizer=True,optimizer=optimizer,script_params=script_params)\n",
    "    estimator.fit(input_data, input_labels, loss=\"nll_loss\", opt=\"SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
